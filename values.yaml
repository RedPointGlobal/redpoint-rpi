global:
  application:
    name: redpoint-interaction
    version: 7

  deployment:
    # Specify the cloud environment where the deployment will run.
    # Supported options: azure, amazon, google, selfhosted
    # "selfhosted" is intended for on-premise or non-cloud based kubernetes deployments.
    platform: amazon

    # List of images
    images:
      interactionapi: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-interactionapi
      integrationapi: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-integrationapi
      executionservice: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-executionservice
      nodemanager: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-nodemanager
      callbackapi: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-callbackapi
      deploymentapi: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-deploymentapi
      # Optional: If not using RPI Realtime, these are not needed
      realtimeapi: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-realtimeapi
      queuereader: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-queuereader
      # Optional: If using external (BYO) Redis or RabbitMQ servers, these are not needed.
      rabbitmq: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rabbitmq
      rediscache: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rediscache
      # Optional: If using external (BYO) ingress controller, this is not needed
      ingress_controller: rg1acrpub.azurecr.io/docker/redpointglobal/releases/nginx-ingress-controller
      # Optional: Only required for network-related troubleshooting/debugging.
      net_utils: rg1acrpub.azurecr.io/docker/redpointglobal/releases/net-utils:latest
      rediscommander: rg1acrpub.azurecr.io/docker/redpointglobal/releases/redis-commander:latest
      # Specific version of RPI to be deployed, where <major.minor>.<year>-<MMDD>-<HHMM>
      cdpauthservices: rg1acrpub.azurecr.io/docker/redpointglobal/releases/cdp-authservice
      cdpinitservice: rg1acrpub.azurecr.io/docker/redpointglobal/releases/cdp-init
      cdpservicesapi: rg1acrpub.azurecr.io/docker/redpointglobal/releases/cdp-servicesapi
      cdpuiservice: rg1acrpub.azurecr.io/docker/redpointglobal/releases/cdp-ui
      cdpsocketio: rg1acrpub.azurecr.io/docker/redpointglobal/releases/cdp-socketio
      cdpmaintenanceservice: rg1acrpub.azurecr.io/docker/redpointglobal/releases/cdp-maintenance
      keycloak: rg1acrpub.azurecr.io/docker/redpointglobal/releases/keycloak
      tag: 7.6.20251107.936
      # Pull the image only if it's not already present on the node
      imagePullPolicy: IfNotPresent
      # Use an image pull secret for private registry authentication
      imagePullSecret:
        enabled: true
        # Name of the Kubernetes secret containing registry credentials
        name: redpoint-rpi

# ==========================
databases:
  # Operational database providers 
  operational:
    # Supported options:
    # - sqlserver (can be hosted on Azure, Google Cloud, AWS RDS)
    # - postgresql (can be hosted on Azure, Google Cloud, AWS RDS)
    # - sqlserveronvm (SQL Server on a Virtual Machine)
    provider: sqlserver
    # The hostname or IP address of the database server
    server_host: <my-database-server-host>
    # The username for accessing the database
    server_username: <my-database-server-username>
    # The password for the given username
    server_password: <my-database-server-password>
    # The name of the operational database
    pulse_database_name: <my-pulse-database-name>
    # The name of the logging database
    pulse_logging_database_name: <my-logging-database-name>
    # The schema to be used within the database
    databaseSchema: dbo
    # When set to true, appends `Encrypt=True` to the SQL Server connection string.
    # If your SQL Server enforces encryption (e.g., Force Encryption is enabled) this must be set to true
    encrypt: true
    # Supported options are OperatingSystem and Database. Defaults to OperatingSystem
    dateTimeSource: OperatingSystem

  # Datawarehouse Providers
  # This section only applies if your datawarehouse is one of Redshift, BigQuery. 
  # Redshift and BigQuery use ODBC drivers, which require a configuration file to be included in the containers. 
  # The details you provide are used to configure the Data Source Name (DSN). 
  # After deployment, the connection string for your Redshift or BigQuery data warehouse would look 
  # like this: ```dsn=rsh-tenant1``` or ```dsn=gbq-tenant1``` 
  datawarehouse:
    # Only update the fields relevant to your datawarehouse requirements
    # For example, if you're using Redshift, update the Redshift fields
    # If you are using both  redshift and bigquery, provide values for both.
    # Supported options: (redshift, bigquery)
    # ==========================
    # Configuration for Redshift
    redshift:
      enabled: true
      connections:
        # Redshift credentials for Tenant 1
        - name: rsh-tenant1
          server: redshift-tenant1.endpoint.aws
          port: 5439
          database: db_tenant1
          username: user1
          password: pass1
        # Redshift credentials for Tenant 2
        - name: rsh-tenant2
          server: redshift-tenant2.endpoint.aws
          port: 5439
          database: db_tenant2
          username: user2
          password: pass2
    # ==========================
    # Configuration for BigQuery
    # Add a new entry for each RPI client requiring a connection to GBQ.
    # To remove a client, delete or comment out the corresponding entry.
    bigquery:
      enabled: false
      connections:
        # Bigquery credentials for Tenant 1
        - name: gbq-tenant1
          # The Google Cloud Project ID
          projectId: gbq-tenant1
          # SQL dialect option (1 = Standard SQL)
          sqlDialect: 1
          # OAuth mechanism (0 = Service Account, 1 = User Credentials)
          OAuthMechanism: 0 
          credentialsType: serviceAccount
          # Service account email
          serviceAccountEmail: gbq-tenant1@my-project.iam.gserviceaccount.com 
          # Create a ConfigMap containing the service account JSON credentials file 
          # and provide the name below
          configMapName: gbq-tenant1 
          # Name of the service account JSON key
          keyName: gbq-tenant1.json
          # Path to the service account JSON key file
          ConfigMapFilePath: /app/google-creds
          # AllowLargeResults: When set to 1, the driver allows for result sets in responses to be larger than 128 MB.
          allowLargeResults: 0
          # LargeResultsDataSetId: DatasetId to store temporary tables created.  This is a required setting if AllowLargeResults is set to 1.
          largeResultsDataSetId: _bqodbc_temp_tables
          # LargeResultsTempTableExpirationTime: Time in milliseconds before the temporary tables created expire.  
          # This is a required setting if AllowLargeResults is set to 1.
          largeResultsTempTableExpirationTime: "3600000"
    # ==========================
    # Snowflake Configuration
    # This section configures access to a Snowflake data warehouse using RSA key pair authentication,
    # which provides enhanced security compared to basic authentication (username and password).
    # Apply this configuration if your Snowflake instance requires RSA key-based authentication.
    # ********** This feature will be available starting with the upcoming RPI 7.7 release ****************
    snowflake:
      enabled: false
      # Supported options are password, snowflake_jwt
      credentialsType: password
      # Name of the ConfigMap storing Snowflake credentials
      ConfigMapName: snowflake-creds
      # Name of the RSA key for authentication
      keyName: my-snowflake-rsakey.p8
      # Mount path for the credentials in the container
      ConfigMapFilePath: /app/snowflake-creds
      # In RPI, use the following format for the Snowflake connection string:
      # User=<snowflakeUser>;Db=<snowflakeDB>;host=<snowflakeHost>;Account=<snowflake account>;AUTHENTICATOR=snowflake_jwt;PRIVATE_KEY_FILE=/app/snowflake-creds/my_snowflake_rsa_key.p8;PRIVATE_KEY_PWD=<privateKeyPassword>
    # Let the Helm chart automatically create the secret containing the credentials
    autoCreateSecrets: true
    # ==========================
    # Databricks Configuration
    databricks:
      enabled: false
      connections:
        - name: dbx-tenant1
          host: my-host.2.azuredatabricks.net
          port: 443
          httpPath: /sql/1.0/warehouses/c546e1e69e8d2ac9
  #      - name: dbx-tenant2
  #        host: my-host.2.azuredatabricks.net
  #        port: 443
  #        httpPath: /sql/1.0/warehouses/c546e1e69e8d2ac9

# ==========================
# Certain RPI functionality (e.g., secret managers, Azure and GCP plugins) is able to make use of 
# cloud provider identity to authenticate with cloud services.
cloudIdentity:
  enabled: false
  # Authentication method for accessing cloud services.
  # Supported options: Azure, Google, Amazon
  provider: Amazon
  secretsManagement:
    enabled: false
    # Specify how to reference required secrets, such as database passwords and connection strings.
    # Supported options: 'kubernetes' or 'keyvault'
    #
    # - Use 'kubernetes' to have the Helm chart automatically create the secrets within your Kubernetes cluster.
    # - Use 'keyvault' to disable Kubernetes secret creation and pull secrets from an external key vault.
    #
    # For more information, refer to the ```Configure Secrets Management``` in the README.md
    secretsProvider: kubernetes
    # If secretsProvider is kubernetes - Let the Helm chart automatically create the secret
    autoCreateSecrets: true
    # Name of the kubernetes secret to be created
    secretName: redpoint-rpi-secrets
    # Use Key Vault for system configuration passwords
    UseForConfigPasswords: true
    UseForAppSettings: true
    # Interval in seconds to reload configuration from Key Vault
    ConfigurationReloadIntervalSeconds: 30
  azureSettings:
    # Supported options: workloadIdentity
    credentialsType: workloadIdentity
    managedIdentityClientId: your_managed_identity_client_id
    UseADTokenForDatabaseConnection: false
    # If your secretsProvider is keyvault
    vaultUri: https://myvault.vault.azure.net/
    appSettingsVaultUri: https://myvault.vault.azure.net/
  googleSettings:
    credentialsType: serviceAccount
    # Create a ConfigMap containing the service account JSON credentials file 
    # and provide the name below
    configMapName: my-google-svs-account
    keyName: my-google-svs-account.json
    ConfigMapFilePath: /app/google-creds
    serviceAccountEmail: my-google-svs-account@my-project.iam.gserviceaccount.com
    # Name of google project
    projectId: your_google_project_id
  amazonSettings:
    credentialsType: accessKey
    accessKeyId: <my-aws-iam-access-key>
    secretAccessKey: <my-aws-iam-secret-access-key>
    region: us-east-1  

# ==========================      
storage:
  # Configure storage for the RPI File Output and Data Management (RPDM) upload directories.
  # This chart is intentionally storage agnostic and does not enforce any specific storage solution.
  # You are responsible for creating the appropriate storage configuration based on your cloud providerâ€™s requirements.
  # Provide the name of the Persistent Volume Claim (PVC) to be used below.
  # If storage is not needed, set 'enabled' to false.
  persistentVolumeClaims:
    FileOutputDirectory:
      enabled: false
      claimName: rpifileoutputdir
      mountPath: /rpifileoutputdir
    Plugins:
      enabled: false
      claimName: realtimeplugins
      mountPath: /app/plugins
    DataManagementUploadDirectory:
      enabled: false
      claimName: rpdmuploaddirectory
      mountPath: /rpdmuploaddirectory

# ==========================
realtimeapi:
  # If disabled, the realtime pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  name: rpi-realtimeapi
  serviceAccount: 
    enabled: true
  # Ensure this matches your target RPI client ID.
  rpiClientID: 00000000-0000-0000-0000-000000000000
  # The default authentication method for the Realtime API is an authentication 
  # token in the header of the call to the API endpoint
  authentication:
    # Supported options are 
    # - basic
    # - oauth
    type: basic
    # With basic authentication, methods protected by the Standard role do not require an RPIAuthKey 
    # authentication token whereas the rest require a token.
    basic:
      authToken: 00000000-0000-0000-0000-000000000000
      standard: false
      forms: true
      listenerQueue: true
      recommendations: true
    # Once OAuth authentication is enabled, it takes precedence over the usage of static token authentication.
    # An RPI Realtime authentication database must be made available, and 
    # Refer to https://docs.redpointglobal.com/rpi/rpi-realtime-authentication
    oauth:
      databaseName: RPIRealtimeCore
      accessTokenLifetimeSeconds: 360
      refreshTokenLifetimeSeconds: 360
  # Expose the Realtime API Swagger page for API exploration and testing.
  enableHelpPages: true 
  enableEventListening: true
  realtimeProcessingEnabled: true
  CORSOrigins: ["*"]
  ThresholdBetweenSiteVisitsMinutes: 30
  CacheWebFormData: true
  decisionCacheDuration: 60
  enableAuditMetricsInHeaders: true
  # If set, profile data will be sent via queue to RPI
  cacheOutputQueueEnabled: true
  RealtimeServerCookieEnabled: false
  ThresholdBetweenSiteVisitsMinutes: 120
  ThresholdBetweenPageVisitsMinutes: 1
  CacheOutputCollectIPAddress: true
  CacheWebFormData: false
  HashVisitorID: false
  EventListeningLocalCacheDuration: 60
  RealtimeServerCookieHttpOnly: false
  RealtimeServerCookieName: rg-visitor
  RealtimeServerCookieExpires: 60
  RealtimeServerCookieDomain: ""
  cacheProvider:
    # This section defines the settings for the real-time cache provider.
    # Update only the fields relevant to your chosen provider and leave the others unchanged.
    # Set to true to enable real-time cache configuration.
    enabled: true  
    # Choose your cache provider
    # Supported options: (mongodb, azureredis, redis, inMemorySql, googlebigtable).
    provider: mongodb
    # If using MongoDB as the provider
    mongodb:
      # Provide the MongoDB connection string.
      connectionString: mongodb://<my_username>:<my_password>@myserver.mongodb.net:27017/Pulse?authSource=admin&ssl=true
      databaseName: <my-realtime-cache-db>
      collectionName: <my-realtime-cache-collection>

    # If using Azure Redis as the provider
    azureredis: 
      # Provide the Azure Redis server host URL.
      connectionstring: redis://<my-redis-name>.redis.cache.windows.net:6380?ssl=true&password=<my-access-key>

    # If using Redis as the provider
    redis:
      # Set to true to deploy an internal Redis container.
      # Set to false if using an external (BYO) Redis instance.
      internal: false
      replicas: 1
      # Redis connection string used when 'internal' is false.
      # Format: <hostname>:<port>,ssl=<true|false>,abortConnect=<true|false>,user=<username>,password=<password>
      connectionstring: <my-redis-hostname>:6379,ssl=True,abortConnect=false,user=<my-username>,password=<my-username>
      resources:
        enabled: true
        requests:
          cpu: 256m
          memory: 1Gi
        limits:
#          cpu: 2
          memory: 1Gi

    # In-memory SQL cache configuration
    inMemorySql:
      # Hostname or IP address of the cache database server
      server_host: <my-cache-database-server-host>
      # Name of the in-memory SQL database
      database_name: <my-cache-database-name>
      # Credentials for database access
      username: <my-cache-database-username>
      password: <my-cache-database-password>
    
    googlebigtable:
      projectId: <my-bigtable-project-id>
      instanceId: <my-bigtable-instance-id>
      
  queueProvider:
    # This section defines the settings for the real-time message queue provider.
    # Set to true to enable real-time queue configuration
    enabled: true  
    # Choose your message queue provider
    # Supported options: (amazonsqs, azureservicebus, googlepubsub, azureeventhubs, rabbitmq)
    provider: amazonsqs  
    queueNames: 
      # Queues required by the RPI Realtime service
      # Ensure that you replace these values with the actual names of the queues 
      # that are allocated for your specific environment.
      formQueuePath: RPIWebFormSubmission
      eventsQueuePath: RPIWebEvents
      cacheOutputQueuePath: RPIWebCacheData
      recommendationsQueuePath: RPIWebRecommendations
      # Overrides the standard queue settings for event stream processing
      listenerQueuePath: RPIQueueListener
      callbackServiceQueuePath: RPICallbackApiQueue
    # Update only the fields relevant to your chosen provider and leave the others unchanged.
    # If using AWS SQS as the provider
    amazonsqs:
      # Specify the authentication method for accessing Amazon SQS.
      # Supported options:
      #   - accessKey: Use static AWS access key and secret key (configure these under the cloudIdentity.amazonSettings section above).
      credentialsType: accessKey
      visibilityTimeout: "301"

    # If using Azure Service Bus as the queue provider
    azureservicebus:
      # Provide the Azure Service Bus connection string
      connectionstring: Endpoint=sb://<my-service-bus-namespace>.servicebus.windows.net/;SharedAccessKeyName=<my-policy-name>;SharedAccessKey=<my-policy-key>

    # If using Google Pub/Sub as the queue provider
    googlepubsub:
      # Provide the Google Cloud project ID
      projectId: <my-google-project-id>

    # If using Azure Event Hubs as the queue provider
    azureeventhubs:
      # Provide the Azure Event Hub connection string
      connectionstring: Endpoint=sb://<my-event-hubs-namespace>.servicebus.windows.net/;SharedAccessKeyName=<my-policy-name>;SharedAccessKey=<my-policy-key>;EntityPath=<my-event-hub-name>
      eventHubName: RPIQueueListener
      SendMessageBatchSize: 200
      ReceiveMessageBatchSize: 200
      # EventHub namespace name
      NamespaceName: my_eventhub_namespace_name
      PartitionIds:
        - "0"
      #  - "1"
    # If using RabbitMQ as the queue provider
    rabbitmq:
      # Type of RabbitMQ to use:
      # - internal: use the RabbitMQ instance created by the Helm chart
      # - external: use an externally hosted RabbitMQ service
      type: internal
      rabbitmqSettings:
      #  When using the internal RabbitMQ instance:
      #   - Replace `{{ .Release.Namespace }}` with the namespace where this Helm release is deployed.
      # - For external RabbitMQ: replace the entire value with the hostname and port for broker.
        hostname: rpi-realtimeapi-rabbitmq-0.rpi-realtimeapi-rabbitmq.{{ .Release.Namespace }}.svc.cluster.local
        username: redpointrpi
        # Password used to authenticate with the RabbitMQ instance.
        # - Required if using the internal RabbitMQ instance created by this Helm chart.
        password: my_Super_Strong_Pwd
        virtualhost: /
        resources:
          enabled: true
          requests:
            cpu: 500m
            memory: 750Mi
          limits:
            cpu: "1"
            memory: 3Gi
        volumeClaimTemplates:
          enabled: true
          storage: "50Gi"
      autoscaling:
        type: hpa
        minReplicas: 2
        maxReplicas: 5
        targetCPUUtilizationPercentage: 80
        targetMemoryUtilizationPercentage: 80
    # If using Amazon Managed Kafka (MSK) as the queue provider
    amazonmsk:
      region: <my-aws-region>
      accessKeyId: <my-aws-iam-access-key>
      secretAccessKey: <my-aws-iam-secret-access-key>
      bootstrapServers: <my-server1.c2.kafka.us-east-1.amazonaws.com:9198>
      Acks: None
      CompressionType: Snappy
      MaxRetryAttempt: 10
      BatchSize: "1000000"
      LingerTime: 0
      UseAwsMsk: True
  dataMaps:
    visitorProfile:
      DaysToPersist: 365
      CompressData: true
    visitorHistory:
      DaysToPersist: 365
      CompressData: true
    nonVisitorData:
      DaysToPersist: 365
      CompressData: true
    productRecommendation:
      DaysToPersist: 365
      CompressData: true
    offerHistory:
      DaysToPersist: 365
      CompressData: true
    messageHistory:
      DaysToPersist: 365
      CompressData: true
  idValidation:
    enableVisitorIDValidation: true
    visitorID:
      minimumLength: 1
      maximumLength: 36
      enableLetters: true
      enableNumbers: true
      permittedCharacters:
        - "-"
        - "_"
        - "/"
        - "."
        - "@"
        - "#"
        - "&"
        - "?"
    enableDeviceIDValidation: true
    deviceID:
      minimumLength: 1
      maximumLength: 36
      enableLetters: true
      enableNumbers: true
      permittedCharacters:
        - "-"
        - "_"
        - "/"
        - "."
        - "@"
        - "#"
        - "&"
        - "?"

  # Custom plugin configuration
  customPlugins:
    # Enable of disabled the configuration
    enabled: false
    # List of plugin definitions to inject into the application via environment variables.
    # To define multiple plugins, simply add each as a new entry in the list below.
    # To remove a plugin, simply remove the entry from the list.
    list:
      # --------------------- Pre-Decision Example
      - name: Pre-Decision Example
        factory:
          assembly: RedPoint.Realtime.Example.Plugins
          type: RealtimeExamplePlugin.Decisions.PreDecisionPluginFactory
        type:
          name: Predecision
          # Optional: Possible values are Include, Exclude
          apiContentFilterOperator: "Include" 
          # Optional: Define one or more API context filters.
          # Uncomment to add a filter.
          apiContextFilters:
            - apply-plugin
        settings:
          - key: Param1
            value: my-custom-parameter1
          - key: Param2
            value: my-custom-parameter2
          #- key: key2
          #  value: value2
          #- key: key3
          #  value: value3
          # If a setting requires a collection of values, these can be supplied as per the example below
          # Uncomment and customize the block below as needed:
          #- key: ParamList 
          #  values:
          #    - val1
          #    - val2
          #    - val3
      # --------------------- Post-Decision Example
      - name: Post-Decision Example
        factory:
          assembly: RedPoint.Realtime.Example.Plugins
          type: RealtimeExamplePlugin.Decisions.PostDecisionFactory
        type:
          name: Postdecision
          # Optional: Possible values are Include, Exclude
          apiContentFilterOperator: "" 
          # Optional: Define one or more API context filters.
          # Uncomment to add a filter.
          apiContextFilters:
          #  - filter1
        settings:
          - key: Prefix
            value: my-custom-prefix
          - key: Suffix
            value: my-custom-suffix
          #- key: key2
          #  value: value2
          #- key: key3
          #  value: value3
          # If a setting requires a collection of values, these can be supplied as per the example below
          # Uncomment and customize the block below as needed:
          #- key: ParamList 
          #  values:
          #    - val1
          #    - val2
          #    - val3
      # --------------------- Smart Asset Result Example
      - name: Smart Asset Result Plugin Example
        factory:
          assembly: RedPoint.Realtime.Example.Plugins
          type: RealtimeExamplePlugin.Decisions.SmartAssetPluginFactory
        type:
          name: SmartAssetResults
          # Optional: Possible values are Include, Exclude
          apiContentFilterOperator: "" 
          # Optional: Define one or more API context filters.
          # Uncomment to add a filter.
          apiContextFilters:
            - apply-plugin
          #  - filter2
        settings:
          - key: ParameterName1
            value: MySmartAssetPluginCounter1
          - key: ParameterName2
            value: MySmartAssetPluginCounter2
          #- key: key2
          #  value: value2
          #- key: key3
          #  value: value3
          # If a setting requires a collection of values, these can be supplied as per the example below
          # Uncomment and customize the block below as needed:
          #- key: ParamList 
          #  values:
          #    - val1
          #    - val2
          #    - val3
      # --------------------- Event Plugin Example
      - name: Event Plugin Example
        factory:
          assembly: RedPoint.Realtime.Example.Plugins
          type: RealtimeExamplePlugin.Events.EventPluginFactory
        type:
          name: Event
          # Optional: Possible values are Include, Exclude
          apiContentFilterOperator: "" 
          # Optional: Define one or more API context filters.
          # Uncomment to add a filter.
          apiContextFilters:
          #  - apply-plugin
          #  - filter2
        settings:
          - key: Param1
            value: my-custom-parameter1
          - key: Param2
            value: my-custom-parameter2
          #- key: key2
          #  value: value2
          #- key: key3
          #  value: value3
          # If a setting requires a collection of values, these can be supplied as per the example below
          # Uncomment and customize the block below as needed:
          #- key: ParamList 
          #  values:
          #    - val1
          #    - val2
          #    - val3
      # --------------------- Form Processing Plugin Example
      - name: Form Processing Plugin Example
        factory:
          assembly: RedPoint.Realtime.Example.Plugins
          type: RealtimeExamplePlugin.Forms.FormProcessingFactory
        type:
          name: FormProcessing
          # Optional: Possible values are Include, Exclude
          apiContentFilterOperator: "" 
          # Optional: Define one or more API context filters.
          # Uncomment to add a filter.
          apiContextFilters:
          #  - apply-plugin
          #  - filter2
        settings:
          - key: extrafield1
            value: my-value
          - key: extrafield2
            value: my-value
          #- key: key2
          #  value: value2
          #- key: key3
          #  value: value3
          # If a setting requires a collection of values, these can be supplied as per the example below
          # Uncomment and customize the block below as needed:
          #- key: ParamList 
          #  values:
          #    - val1
          #    - val2
          #    - val3
      # --------------------- Visitor Profile Plugin Example
      - name: Visitor Profile Plugin Example
        factory:
          assembly: RedPoint.Realtime.Example.Plugins
          type: RealtimeExamplePlugin.Visitor.VisitorCachePluginFactory
        type:
          name: Visitor
          # Optional: Possible values are Include, Exclude
          apiContentFilterOperator: "" 
          # Optional: Define one or more API context filters.
          # Uncomment to add a filter.
          apiContextFilters:
          #  - apply-plugin
          #  - filter2
        settings:
          - key: Param1
            value: my-custom-parameter
          - key: Param2
            value: my-custom-parameter
          #- key: key2
          #  value: value2
          #- key: key3
          #  value: value3
          # If a setting requires a collection of values, these can be supplied as per the example below
          # Uncomment and customize the block below as needed:
          #- key: ParamList 
          #  values:
          #    - val1
          #    - val2
          #    - val3
          
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: 500m
      memory: 750Mi
    limits:
#      cpu: 2
      memory: 3Gi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: Error
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5
    
  podDisruptionBudget:
    enabled: false
    maxUnavailable: 0

# ==========================
callbackapi:
  # If disabled, the callbackapi pod will not be deployed
  name: rpi-callbackapi
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  channelLabel: SendGrid
  # Each RPI client requires its own dedicated CallbackAPI instance.  
  # Enable multitenancy to automatically provision a dedicated instance for each client. 
  multitenancy: 
    enabled: false
  # To add a new callbackapi, simply append a new entry to this list.
  # To remove one, delete or comment out the corresponding entry.
  instances:
    - name: "tenant1"
      replicas: 1
#    - name: "client2"
#      replicas: 1
  serviceAccount: 
    enabled: true 
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: 500m
      memory: 750Mi
    limits:
#      cpu: 2
      memory: 3Gi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: Error
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5

  podDisruptionBudget:
    enabled: false
    maxUnavailable: 0

# ==========================      
executionservice:
  # If disabled, the executionservice pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  enableRPIAuthentication: true
  serviceAccount: 
    enabled: true 
  jobExecution:
    internalAddress: ""
    auditTaskEvents: true
    maxThreadsPerExecutionService: 50
    executionShutdownWaitForActivity: "00:08:00"
    overrideCustomSQLReservedWords: false
    maxSmartAssetInstancesForOfferCodes: "100000"
    rpdmOApiPrefixUri: /v1/
    taskTimeout: 60
    triggerCheckCriteriaInterval: 60
    triggersMaxDaysInactive: 180
    defaultMaintenanceModeBufferTime: "00:05:00"
    workflowPrioritization:
      enabled: true
      maxConcurrentWorkflowActivities: 100
      maximumQueueTime: "24:00:00"
  internalCache:
    enabled: true
    # Type of Redis cache to use:
    # - internal: use the Redis instance created by the Helm chart
    # - external: use an externally hosted Redis service (e.g., Azure Redis Cache)
    type: internal
    # Interval at which cache data is backed up to OpsDB (HH:MM:SS)
    backupToOpsDBInterval: "00:00:20"
    maxNumberRetries: "100"
    maxRetryDelay: "00:01:00"
    failOnPrimaryDataLoss: true
    failOnCacheConnectionError: true
    redisSettings: 
      # Password used to authenticate with the Redis instance.
      # - Required if using the internal Redis instance created by this Helm chart.
      password: my_Super_Strong_Pwd
      #  When using the internal Redis instance:
      #   - Replace `{{ .Release.Namespace }}` with the namespace where this Helm release is deployed.
      #   - Replace '{{ myPassword }}` with the one defined above under `redisSettings.password`.
      # - For external Redis: replace the entire value with the connection string for your external Redis instance.
      connectionString: "rpi-executionservice-cache-0.rpi-executionservice-cache.{{ .Release.Namespace }}.svc.cluster.local,password={{ myPassword }},abortConnect=False"
      # Run only one Redis cache pod to prevent split-brain scenarios.
      replicas: 1
      resources:
        enabled: true
        requests:
          cpu: 256m
          memory: 3Gi
        limits:
#          cpu: 2
          memory: 3Gi
      volumeClaimTemplates:
        enabled: true
        storage: "50Gi"
      podDisruptionBudget:
        enabled: true
        maxUnavailable: 0
  luxsci:
    sandbox_mode:
      enabled: false
  seedService:
    memoryCacheSize: "10"
    maxNumberRetries: "100"
    maxRetryDelay: "00:01:00"
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: "2"
      memory: 3Gi
    limits:
#      cpu: "2"
      memory: 3Gi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: Error

  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    # Available options:
    # - "keda": Enables scaling based on custom RPI metrics from Prometheus using KEDA. 
    #    Requires KEDA to be installed in your cluster.
    #    Installation guides: 
    #      - https://keda.sh/docs/latest/deploy/
    #      - https://learn.microsoft.com/en-us/azure/aks/keda-about
    #      - https://learn.microsoft.com/en-us/azure/aks/keda-workload-identity?source=recommendations
    #
    # - "hpa": Uses the native Kubernetes Horizontal Pod Autoscaler to scale
    #   based on CPU and/or memory usage. Does not require any additional components.
    # Note: **KEDA is the recommended scaling solution for the Execution Service**
    type: hpa

    # HPA Settings
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
    
    # KEDA Settings
    kedaScaledObject:
       # The Prometheus server URL that KEDA will query for metrics.
      serverAddress: <my-prometheus-query-endpoint>
      # Set to false if Prometheus doesn't require authentication
      useTriggerAuthentication: true
      # Name of the TriggerAuthentication resource for KEDA to authenticate with Prometheus.
      authenticationRef: rpi-executionservice
      # If using Azure Managed Prometheus in AKS with Workload Identity.
      # - This should be the Client ID of the User-Assigned Managed Identity (UAMI).
      # - The identity must be referenced in the TriggerAuthentication resource.
      # - Relevant Docs: https://learn.microsoft.com/en-us/azure/aks/keda-workload-identity
      identityId: <my-workload_identity-id>
      # The name of the Prometheus metric used by KEDA to make scaling decisions.
      metricName: execution_max_thread_count
      # PromQL query to fetch the current value of the custom metric.
      # Example filters:
      # - Kubernetes Namespace: "<my-rpi-namespace>"
      # - App Label: "rpi-executionservice"
      # - Azure Workload Identity Label: "true"
      # Update these labels if your namespace, app, or identity settings are different.
      query: sum(execution_max_thread_count{kubernetes_namespace="<my-rpi-namespace>", app="rpi-executionservice"})
      # The target value for the metric. When the metric exceeds this threshold,
      # KEDA will trigger a scale-out event.
      threshold: "80"
      # How often (in seconds) KEDA polls Prometheus for the metric value.
      pollingInterval: 30
      # The minimum number of pods to maintain at all times, even when there is little or no load.
      minReplicaCount: 2
      # The maximum number of pods KEDA can scale up to, based on the metric value and scaling policies.
      maxReplicaCount: 10
      fallback:
        failureThreshold: 3
        replicas: 2
      behavior:
        scaleUp:
          stabilizationWindowSeconds: 300
          policies:
            type: Percent
            value: 100
            periodSeconds: 60
        scaleDown:
          stabilizationWindowSeconds: 300
          policies:
            type: Percent
            value: 50
            periodSeconds: 60
      # Duration, in seconds, that a Pod is allowed to gracefully shut down before it is forcefully killed
      terminationGracePeriodSeconds: 120
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  probes:
    enabled: true
  livenessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 3
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 20
    periodSeconds: 15
    failureThreshold: 5
    timeoutSeconds: 5
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5
  podDisruptionBudget:
    enabled: false
    maxUnavailable: 0
  extraEnvs:
    - name: Plugins__LuxSci__IsSandboxMode
      enabled: false
      value: "true"
    - name: RPI_MPULSE_UPSERT_CONTACT_DEBUG
      enabled: false
      value: "1"
    - name: RPI_MPULSE_EVENT_UPLOAD_DEBUG
      enabled: false
      value: "1"
    - name: LC_ALL
      enabled: false
      value: "en_US.UTF-8"
    - name: LANG
      enabled: false
      value: "en_US.UTF-8"
    - name: LANGUAGE
      enabled: false
      value: "en_US.UTF-8"
    - name: RPI_MPULSE_EVENT_UPLOAD_FAIL_DEBUG
      enabled: false
      value: "0"
    - name: RPI_MPULSE_EVENT_UPLOAD_SCENARIO
      enabled: false
      value: "1,5,2,3,5,7"
    - name: RPI_MPULSE_SAVE_MPULSE_EVENT_CONTENT_DEBUG
      enabled: false
      value: "1"
    - name: RPI_MPULSE_UPSERT_CONTACT_IMPORT_PATH_DEBUG
      enabled: false
      value: "/rpifileoutputdir/mpulse-debug-path"

# ========================== 
interactionapi: 
  # If disabled, the interactionapi pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  enableRPIAuthentication: true
  authMetaHttpEnabled: true
  enableSwagger: true
  serviceAccount: 
    enabled: true 
  allowSavingLoginDetails: true
  alwaysShowClientsAtLogin: true
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  useExternalUserManagement: false
  resources:
    enabled: true
    requests:
      cpu: 256m
      memory: 3Gi
    limits:
#      cpu: 2
      memory: 3Gi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: Error

  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    # Options: "keda" or "hpa".
    # 
    # - "keda": Enables KEDA (Kubernetes-based Event Driven Autoscaling), allowing scaling based on RPI custom metrics from
    #   Prometheus. This option assumes that KEDA is already installed in your cluster.
    #   If not, you can install it with Documentation: https://keda.sh/docs/latest/deploy/
    #
    # - "hpa": Enables the standard Kubernetes Horizontal Pod Autoscaler, which scales pods based on CPU and/or memory 
    #   usage metrics. This is natively supported by Kubernetes and does not require additional installation.
    #
    # Choose the appropriate option based on your scaling requirements. If you need scaling based on RPI custom metrics, use "keda".
    # For resource-based scaling, use "hpa".
    type: hpa
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5

  podDisruptionBudget:
    enabled: false
    maxUnavailable: 0

# ========================== 
integrationapi:
  # If disabled, the integrationapi pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  enableSwagger: true
  serviceAccount: 
    enabled: true 
  enableRPIAuthentication: true
  authMetaHttpEnabled: false
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: 256m
      memory: 3Gi
    limits:
#      cpu: 2
      memory: 3Gi
  # Username and Password are only required if Data Activation is enabled
  username: integrationapi
  password: <my-integrationapi-password>
  read_timeout: "300000"
  port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: Error
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    # Options: "keda" or "hpa".
    # 
    # - "keda": Enables KEDA (Kubernetes-based Event Driven Autoscaling), allowing scaling based on RPI custom metrics from
    #   Prometheus. This option assumes that KEDA is already installed in your cluster.
    #   If not, you can install it with Documentation: https://keda.sh/docs/latest/deploy/
    #
    # - "hpa": Enables the standard Kubernetes Horizontal Pod Autoscaler, which scales pods based on CPU and/or memory 
    #   usage metrics. This is natively supported by Kubernetes and does not require additional installation.
    #
    # Choose the appropriate option based on your scaling requirements. If you need scaling based on RPI custom metrics, use "keda".
    # For resource-based scaling, use "hpa".
    type: hpa
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5
  podDisruptionBudget:
    enabled: false
    maxUnavailable: 0

# ========================== 
nodemanager:
  # If disabled, the nodemanager pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  serviceAccount: 
    enabled: true 
  enableRPIAuthentication: true
  enableSwagger: true
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: 256m
      memory: 3Gi
    limits:
#      cpu: 2
      memory: 3Gi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: Error

  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5

  podDisruptionBudget:
    enabled: false
    maxUnavailable: 0

# ========================== 
deploymentapi:
  # If disabled, the deploymentapi pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  serviceAccount: 
    enabled: true 
  templateTenant:
    useTemplateFiles: false
    templateTenantFilesPath: "/tmp/templatetenantfiles"
    volumeClaimName: templatetenantfiles
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: 256m
      memory: 1Gi
    limits:
#      cpu: 2
      memory: 1Gi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: Error

# ==========================
queuereader: 
  # If disabled, the queuereader pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  # Configuration for the Queue Reader container introduced in RPI v7.4
  # This component handles the draining of Queue Listener and RPI Realtime queues.
  serviceAccount: 
    enabled: true 
  # Enable or disable processing for specific queues
  isFormProcessingEnabled: true
  isEventProcessingEnabled: true
  isCacheProcessingEnabled: true
  queueListenerEnabled: true
  isCallbackServiceProcessingEnabled: true
  # Queue for storing messages received by inactive triggers.
  # You can customize the queue name as needed.
  listenerQueueNonActiveQueuePath: listenerQueueNonActive
  # Time-to-live (TTL) in days for messages in the inactive trigger queue.
  listenerQueueNonActiveTTLDays: 14
  # Queue for storing messages that encountered errors during processing.
  # You can customize the queue name as needed.
  listenerQueueErrorQueuePath: listenerQueueError
  # Time-to-live (TTL) in days for messages in the error queue.
  listenerQueueErrorTTLDays: 14
  realtimeConfiguration:
    # Distribution mode for high-performance or high-volume transactions
    # Set to true if you require distributed processing
    isDistributed: false
    distributedCache:
      provider: redis
      # Type of Redis cache to use:
      # - internal: use the Redis instance created by the Helm chart
      # - external: use an externally hosted Redis service (e.g., Azure Redis Cache)
      type: internal
      redisSettings:
      # Connection string for your Redis instance.
        password: my_Super_Strong_Pwd
        connectionString: rpi-queuereader-cache-0.rpi-queuereader-cache:6379,password=my_Super_Strong_Pwd,abortConnect=False
        replicas: 1
        resources:
          enabled: true
          requests:
            cpu: "1"
            memory: 3Gi
          limits:
            cpu: "2"
            memory: 3Gi
        volumeClaimTemplates:
          enabled: true
          storage: "50Gi"
        podDisruptionBudget:
          enabled: false
          maxUnavailable: 0
    distributedQueue:
      # Currently, only RabbitMQ is supported.
      provider: rabbitmq
      # Type of RabbitMQ to use:
      # - internal: use the RabbitMQ instance created by the Helm chart
      # - external: use an externally hosted RabbitMQ service
      type: internal
      rabbitmqSettings:
      #  When using the internal RabbitMQ instance:
      #   - Replace `{{ .Release.Namespace }}` with the namespace where this Helm release is deployed.
      # - For external RabbitMQ: replace the entire value with the hostname and port for broker.
        hostname: "rpi-queuereader-rabbitmq-0.rpi-queuereader-rabbitmq.{{ .Release.Namespace }}.svc.cluster.local"
        username: redpointrpi
        # Password used to authenticate with the RabbitMQ instance.
        # - Required if using the internal RabbitMQ instance created by this Helm chart.
        password: my_Super_Strong_Pwd
        virtualhost: /
        resources:
          enabled: true
          requests:
            cpu: 500m
            memory: 750Mi
          limits:
            cpu: "1"
            memory: 3Gi
        volumeClaimTemplates:
          enabled: true
          storage: "50Gi"
    # Comma separated List of RPI client IDs associated with your RPI cluster 
    tenantIds: 
    - 00000000-0000-0000-0000-000000000000
  # Thread pool configuration
  threadPoolSize: 10
  # Timeout duration for processing, in minutes
  timeoutMinutes: 60
  # Maximum number of messages to process in a single batch
  maxBatchSize: 50
  useMessageLocks: true
  resources:
    enabled: true
    requests:
      cpu: 500m
      memory: 750Mi
    limits:
#      cpu: 2
      memory: 3Gi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: Error

  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5

  podDisruptionBudget:
    enabled: false
    maxUnavailable: 0

diagnosticsMode:
  # Enable or disable copying diagnostic logs to Azure Blob Storage
  copytoAzureBlob: 
    enabled: false
    accountName: <yourstorageaccount>
    accessKey: <yourstorageaccount-access-key>
    containerName: <yourstorageaccount-container-name>
    blobServiceEndpoint: https://yourstorage.blob.core.windows.net
    enableCdn: false
    UseDataLakeStorageGen2: false
  # Enable or disable copying diagnostic logs to an SFTP server
  copytoSftp: 
    enabled: false
    sftpHost: <your-sftp-host>
    sftpUsername: <your-sftp-username>
    sftpPassword: <your-sftp-password>
    sftpPort: "22" # <your-sftp-port>
  dotNetTools: 
    enabled: false          # Whether .NET diagnostic tools are enabled
    useGcDump: false        # Whether GC dump collection is enabled
    useCounters: false      # Whether performance counters are collected
    # Leave these values unchanged
    path: /app/dotnet-tools # Path to .NET tools directory
    extractionBaseDir: /tmp # Temporary extraction directory


  # Optional: Only required for network-related troubleshooting/debugging.
  netutils:
    enabled: false
    securityContext:
      runAsNonRoot: true
      runAsUser: 7777       
      runAsGroup: 7777
      readOnlyRootFilesystem: true
      allowPrivilegeEscalation: false
      privileged: false
      appArmorProfile:
        type: RuntimeDefault
      # Capabilities (tune for your use case)
      capabilities:
        drop:
          - ALL
        # e.g., ["NET_RAW"] or ["NET_ADMIN","NET_RAW"]
        add: ["NET_ADMIN","NET_RAW"]             

MicrosoftEntraID:
  enabled: false
  # Interaction Client Client ID
  interaction_client_id: 00000000-0000-0000-0000-000000000000
  # Interaction API Client ID
  interaction_api_id: 00000000-0000-0000-0000-000000000000
  # Azure Tenant ID
  tenant_id: 00000000-0000-0000-0000-000000000000

OpenIdProviders:
  # Set to true to enable OpenID Connect settings.
  enabled: false
  # Name of the OpenID Connect provider. Supported Providers 
  # - KeyCloak
  # - Okta
  # https://docs.redpointglobal.com/rpi/admin-authentication
  name: KeyCloak
  # Authorization host for OpenID Connect
  authorizationHost: https://login.microsoftonline.com/00000000-0000-0000-0000-000000000000/v2.0
  # The Client ID configured within the OpenID provider.
  clientID: 00000000-0000-0000-0000-000000000000
  # Audience for the OpenID Connect authentication request
  audience: api://00000000-0000-0000-0000-000000000000
  # The redirect URL used for retrieving the token, as configured within the OpenID provider.
  redirectURL: https://rpi-interactionapi.example.com
  # Enable or disable refresh tokens
  #  - If refresh tokens are disabled, the client will be logged off once the token expires,
  #  - per the period configured within the OpenID provider.
  enableRefreshTokens: true
  # Validate issuer of the OpenID Connect provider
  #  - When set to true, validates issuer of the OpenID Connect provider 
  #  - (i.e., the authorizationHost must match the issuer name supplied in the access token).
  validateIssuer: false
  # Validate audience of the OpenID Connect provider
  #  - When set to true, validates audience of the OpenID Connect provider 
  #  - (i.e., the audience must match the audience name supplied in the access token)
  validateAudience: true
  # Parameter for id_token_hint during logout
  logoutIdTokenParameter: id_token_hint
  # Custom scopes for OpenID Connect
  #  - This is the list of custom scopes required to request the OpenID access token.
  customScopes: 
  - api://00000000-0000-0000-0000-000000000000/Interaction.Clients
  # Enable or disable management of RPI users directly within OIDC provider (as well as native user management
  supportsUserManagement: false

SMTPSettings:
  SMTP_SenderAddress: noreply-rpi@example.com
  SMTP_SenderName: "Redpoint Global"
  SMTP_Address: your_smtp_host
  SMTP_Port: 587
  EnableSSL: true
  UseCredentials: true
  SMTP_Username: your_smtp_server_username
  SMTP_Password: your_smtp_server_password

# ========================== 
ingress:
  controller:
    # Set enabled to false if you want to disable the creation of the ingress controller
    enabled: true 
  # Set mode to internal for private ingress and public for public ingress
  mode: public 
  # Set certificateSource to acm if your certificate is managed in AWS Certificate Manager 
  privateLink:
    azure:
      enabled: false
  certificateSource: kubernetes # acm
  tlsSecretName: ingress-tls
  className: nginx-redpoint-rpi
  # Subnet name is only required if you set the ingress mode to private
  subnetName: <my-ingress-vpc-subnet-name> 
  # Certificate Arn is only required if you set the certificateSource to acm
  certificateArn: your_acm_certificate_arn
  # Specify the domain name for the ingress resources.
  domain: example.com
  # Add any specific annotations required for your ingress setup here.
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: 4096m
    nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
    nginx.ingress.kubernetes.io/enable-access-log: "true"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"

  customLabels: 
    environment: prod
    team: marketing
  service:
    port: 80
  customAnnotations:
    prometheus.io/scrape: "false"
  # Define hostnames for different services in your application.
  hosts:
    # Deployment API
    config: rpi-deploymentapi
    # Interaction API
    client: rpi-interactionapi
    # Integration API
    integration: rpi-integrationapi
    # Realtime API 
    realtime: rpi-realtimeapi
    # Callback API
    callbackapi: rpi-callbackapi
    # Queue Reader 
    queuereader: rpi-queuereader
    # RabbitMQ console
    rabbitmqconsole: rpi-rabbitmq-console
    # Data Activation Web UI
    dataactivation: rpi-dataactivation

securityContext:
  # Enable this to enforce running the container as a non-root user.
  enabled: true
  runAsUser: 7777
  runAsGroup: 7777
  fsGroup: 7777
  runAsNonRoot: true
  readOnlyRootFilesystem: true
  privileged: false
  allowPrivilegeEscalation: false
  capabilities:
    drop: ["ALL"]
  supplementalGroups:
    - 4000
    - 5000

# NodeSelector is used to control scheduling by specifying node labels.
# When enabled, the deployment will only be scheduled on nodes that match the provided key-value pair.
nodeSelector:
  enabled: false
  key: app
  value: redpoint-rpi

# Tolerations allow the deployment to be scheduled on tainted nodes.
# When enabled, this ensures that the workload can run on nodes explicitly reserved for Redpoint RPI by tolerating their taints.
tolerations:
  enabled: false
  effect: NoSchedule
  key: app
  operator: Equal
  value: redpoint-rpi

# ==========================
redpointAI:
  # Set to true to enable Redpoint AI features
  enabled: false  
  naturalLanguage:
    # your OpenAI API key
    ApiKey: <my-openai-key>
    # Base URL for the OpenAI endpoint             
    ApiBase: https://example.openai.azure.com/
    # API version (e.g., 2023-05-15)            
    ApiVersion: 2023-07-01-preview
    # Name of the deployed ChatGPT engine (e.g., gpt-35-turbo)           
    ChatGptEngine: gpt-4-32k
    # Temperature for ChatGPT responses (e.g., 0.7)        
    ChatGptTemp: 0.5
  cognitiveSearch:
    # Azure Cognitive Search endpoint URL
    SearchEndpoint: https://example.search.windows.net
    # API key for Azure Cognitive Search       
    SearchKey: <my-cognitivesearch-key>
    # Azure Cognitive Search vector profile name    
    VectorSearchProfile: vector-profile-000000000000
    # Azure Cognitive Search vector config name 
    VectorSearchConfig: vector-config-000000000000 
  modelStorage:
    # Azure Blob Storage connection string for model artifacts
    ConnectionString: DefaultEndpointsProtocol=https;AccountName=my_account_name;AccountKey=my_account_access_key 
    # Name of the embeddings model (e.g., text-embedding-ada-002)
    EmbeddingsModel: text-embedding-ada-002
    # Dimensionality of the embeddings (e.g., 1536)            
    ModelDimensions: 1536 
    # Name of the Azure Blob Storage container holding vector index data
    ContainerName: my_blob_container_name
    # Path inside the container where model files are stored       
    BlobFolder: my_blob_container_folder_name

# ==========================
dataActivation:
  # Enables RPI - Smart Activation (Web UI)
  enabled: false
authservice:
  # If disabled, the authentication service will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  default_username: admin@redpointcdp.com
  default_password: <my-default-admin-password>
  serviceAccount: 
    enabled: true
  resources:
    enabled: true
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
#      cpu: 2
      memory: 1Gi
    java_options: -Xmx750m
  port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    verbosity: DEBUG
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  terminationGracePeriodSeconds: 120
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5
  securityContext:
    enabled: true
    runAsUser: 7777
    runAsGroup: 7777
    fsGroup: 7777
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    privileged: false
    appArmorProfile: runtime/default
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
#    supplementalGroups:
#      - 4000
#      - 5000
  rollingUpdate:
    maxUnavailable: "25%"
    maxSurge: "25%"
    progressDeadlineSeconds: 600
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  nodeSelector:
    enabled: true
    key: app
    value: rpclients
  tolerations:
    enabled: true
    effect: NoSchedule
    key: app
    operator: Equal
    value: rpclients

# ==========================
keycloak:
  enabled: true
  type: internal
  replicas: 1
  serviceAccount: 
    enabled: true 
  hostname: keycloak
  username: sso-admin@redpointcdp.com
  password: <my-keycloak-admin-password>
  database_name: CDP_AUTH_{{ .Release.Namespace }}
  realm_name: redpoint-mercury
  realm_client_id: rpi-service
  realm_client_secret: <my-realm-client-secret>
  securityContext:
    enabled: true
    runAsUser: 1001
    runAsGroup: 1001
    fsGroup: 1001
    runAsNonRoot: true
    readOnlyRootFilesystem: false
    privileged: false
    appArmorProfile: runtime/default
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
#    supplementalGroups:
#      - 4000
#      - 5000
  rollingUpdate:
    maxUnavailable: "25%"
    maxSurge: "25%"
    progressDeadlineSeconds: 600
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    # HPA Settings
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5
  resources:
    enabled: true
    requests:
      cpu: 256m
      memory: 1Gi
    limits:
#      cpu: "2"
      memory: 1Gi

# ==========================
reportingservice:
  sigma:
    enabled: true
    api_url: https://api.us.azure.sigmacomputing.com
    client_id: 48dd1982ab835ff53177e9cbd7fb5608b1db8c56491a040f2f0843a3bfc6b440
    client_secret: my_sigma_client_secret

# ==========================
initservice:
  enabled: true
  replicas: 1
  serviceAccount: 
    enabled: true 
  # MongoDB is the only supported option for the operational database
  database:
    operational:
      name: CDP_WEB_{{ .Release.Namespace }}
      connection_string: mongodb+srv://<my_username>:<my_password>@<my_hostname>/?retryWrites=true&w=majority
  securityContext:
    enabled: true
    runAsUser: 7777
    runAsGroup: 7777
    fsGroup: 7777
    runAsNonRoot: true
    readOnlyRootFilesystem: false
    privileged: false
    appArmorProfile: runtime/default
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
#    supplementalGroups:
#      - 4000
#      - 5000
  rollingUpdate:
    maxUnavailable: "25%"
    maxSurge: "25%"
    progressDeadlineSeconds: 600
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  port: 80
  resources:
    enabled: true
    requests:
      cpu: 256m
      memory: 2Gi
    limits:
#      cpu: "2"
      memory: 2Gi
    java_opts: "-Xmx1536m"
  logging:
    verbosity: DEBUG
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    # HPA Settings
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5

# ==========================
messageq:
  replicas: 1
  serviceAccount: 
    enabled: true
  port: 5672
  type: statefulset
  resources:
    enabled: true
    requests:
      cpu: "256m"
      memory: "750Mi"
    limits:
      memory: "2Gi"
  username: "redpointrpi"
  password: "my_Super_Strong_Pwd"
  virtualhost: "/"
  erang_cookie: "1234"
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  securityContext:
    enabled: true
    runAsUser: 7777
    runAsGroup: 7777
    fsGroup: 7777
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    privileged: false
    appArmorProfile: runtime/default
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
#    supplementalGroups:
#      - 4000
#      - 5000
  autoscaling:
    enabled: true
    type: hpa
    # HPA Settings
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  rollingUpdate:
    maxUnavailable: "25%"
    maxSurge: "25%"
    progressDeadlineSeconds: 600
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  volumeClaimTemplates:
    storage: 50Gi
  nodeSelector:
    enabled: true
    key: pool
    value: rg1shared
  tolerations:
    enabled: true
    effect: NoSchedule
    key: pool
    operator: Equal
    value: rg1shared

# ==========================
maintenanceservice:
  enabled: true
  replicas: 1
  serviceAccount: 
    enabled: true 
  securityContext:
    enabled: true
    runAsUser: 7777
    runAsGroup: 7777
    fsGroup: 7777
    runAsNonRoot: true
    readOnlyRootFilesystem: false
    privileged: false
    appArmorProfile: runtime/default
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
#    supplementalGroups:
#      - 4000
#      - 5000
  rollingUpdate:
    maxUnavailable: "25%"
    maxSurge: "25%"
    progressDeadlineSeconds: 600
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  port: 80
  resources:
    enabled: true
    resources:
      enabled: true
      requests:
        cpu: 256m
        memory: 1Gi
      limits:
  #      cpu: "2"
        memory: 1Gi
      java_opts: "-Xmx750m"
  logging:
    verbosity: DEBUG
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    # HPA Settings
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5

# ==========================
servicesapi:
  enabled: true
  replicas: 1
  serviceAccount: 
    enabled: true 
  sso_enabled: true
  securityContext:
    enabled: true
    runAsUser: 7777
    runAsGroup: 7777
    fsGroup: 7777
    runAsNonRoot: true
    readOnlyRootFilesystem: false
    privileged: false
    appArmorProfile: runtime/default
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
#    supplementalGroups:
#      - 4000
#      - 5000
  rollingUpdate:
    maxUnavailable: "25%"
    maxSurge: "25%"
    progressDeadlineSeconds: 600
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  port: 80
  resources:
    enabled: true
    resources:
      enabled: true
      requests:
        cpu: 256m
        memory: 2Gi
      limits:
  #      cpu: "2"
        memory: 2Gi
      java_opts: -Xmx1536m
  logging:
    verbosity: DEBUG
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    # HPA Settings
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5

# ==========================
socketio:
  enabled: true
  replicas: 1
  serviceAccount: 
    enabled: true 
  keycloak_realm: "redpoint-mercury"
  securityContext:
    enabled: true
    runAsUser: 7777
    runAsGroup: 7777
    fsGroup: 7777
    runAsNonRoot: true
    readOnlyRootFilesystem: false
    privileged: false
    appArmorProfile: runtime/default
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
#    supplementalGroups:
#      - 4000
#      - 5000
  rollingUpdate:
    maxUnavailable: "25%"
    maxSurge: "25%"
    progressDeadlineSeconds: 600
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  port: 80
  resources:
    enabled: true
    requests:
      cpu: 256m
      memory: 1Gi
    limits:
#      cpu: "2"
      memory: 1Gi
    java_opts: -Xmx750m
  logging:
    verbosity: DEBUG
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    # HPA Settings
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5

# ==========================
uiservice:
  enabled: true
  replicas: 1
  serviceAccount: 
    enabled: true 
  securityContext:
    enabled: true
    runAsUser: 7777
    runAsGroup: 7777
    fsGroup: 7777
    runAsNonRoot: true
    readOnlyRootFilesystem: false
    privileged: false
    appArmorProfile: runtime/default
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
#    supplementalGroups:
#      - 4000
#      - 5000
  rollingUpdate:
    maxUnavailable: "25%"
    maxSurge: "25%"
    progressDeadlineSeconds: 600
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  port: 80
  resources:
    enabled: true
    requests:
      cpu: 256m
      memory: 2Gi
    limits:
#      cpu: "2"
      memory: 2Gi
    java_opts: -Xmx1536m
  logging:
    verbosity: DEBUG
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    # HPA Settings
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5
    
# ==========================
cdpcache:
  enabled: true
  replicas: 1
  serviceAccount: 
    enabled: true 
  securityContext:
    enabled: true
    runAsUser: 7777
    runAsGroup: 7777
    fsGroup: 7777
    runAsNonRoot: true
    readOnlyRootFilesystem: false
    privileged: false
    appArmorProfile: runtime/default
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
#    supplementalGroups:
#      - 4000
#      - 5000
  rollingUpdate:
    maxUnavailable: "25%"
    maxSurge: "25%"
    progressDeadlineSeconds: 600
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  port: 80
  resources:
    enabled: true
    requests:
      cpu: 256m
      memory: 1Gi
    limits:
#      cpu: 2
      memory: 1Gi
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    # HPA Settings
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 40
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    initialDelaySeconds: 10
    failureThreshold: 30
    periodSeconds: 10
    timeoutSeconds: 5
  volumeClaimTemplates:
    storage: "50Gi"