global:
  application:
    name: redpoint-interaction
    version: 7

  deployment:
    # Specify the cloud environment where the deployment will run.
    # Supported options: azure, amazon, google, selfhosted
    # "selfhosted" is intended for on-premise or non-cloud based kubernetes deployments.
    platform: amazon

    # List of images
    images:
      interactionapi: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-interactionapi
      integrationapi: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-integrationapi
      executionservice: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-executionservice
      nodemanager: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-nodemanager
      callbackapi: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-callbackapi
      deploymentapi: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-deploymentapi
      # If not using RPI Realtime, these are not needed
      realtimeapi: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-realtimeapi
      queuereader: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rpi-queuereader
      # If using external (BYO) Redis or RabbitMQ servers, these are not needed.
      rabbitmq: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rabbitmq
      rediscache: rg1acrpub.azurecr.io/docker/redpointglobal/releases/rediscache
      # If using external (BYO) ingress controller, this is not needed
      ingress_controller: rg1acrpub.azurecr.io/docker/redpointglobal/releases/nginx-ingress-controller
    
      # Specific version of RPI to be deployed, where <major.minor>.<year>-<MMDD>-<HHMM>
      tag: 7.6.20250723.1344
      # Pull the image only if it's not already present on the node
      imagePullPolicy: IfNotPresent
      # Use an image pull secret for private registry authentication
      imagePullSecret:
        enabled: true
        # Name of the Kubernetes secret containing registry credentials
        name: redpoint-rpi

# ==========================
databases:
  # Operational database providers 
  operational:
    # Supported options:
    # - sqlserver (can be hosted on Azure, Google Cloud, AWS RDS)
    # - postgresql (can be hosted on Azure, Google Cloud, AWS RDS)
    # - sqlserveronvm (SQL Server on a Virtual Machine)
    provider: sqlserver
    # The hostname or IP address of the database server
    server_host: <my-database-server-host>
    # The username for accessing the database
    server_username: <my-database-server-username>
    # The password for the given username
    server_password: <my-database-server-password>
    # The name of the operational database
    pulse_database_name: <my-pulse-database-name>
    # The name of the logging database
    pulse_logging_database_name: <my-logging-database-name>
    # The schema to be used within the database
    databaseSchema: dbo
    # When set to true, appends `Encrypt=True` to the SQL Server connection string.
    # If your SQL Server enforces encryption (e.g., Force Encryption is enabled) this must be set to true
    encrypt: true
    # Supported options are OperatingSystem, Database
    dateTimeSource: OperatingSystem

  # Datawarehouse Providers
  # This section only applies if your datawarehouse is one of Redshift, BigQuery or snowflake. 
  # Redshift and BigQuery use ODBC drivers, which require a configuration file to be included in the containers. 
  # The details you provide are used to configure the Data Source Name (DSN). 
  # After deployment, the connection string for your Redshift or BigQuery data warehouse would look 
  # like this: ```dsn=redshift``` or ```dsn=bigquery``` 
  datawarehouse:
    enabled: true
    # Only update the fields relevant to your chosen option and leave the others unchanged.
    # For example, if you're using Redshift, update the Redshift fields and leave Snowflake, BigQuery fields as-is.
    # Supported options: (redshift, bigquery, snowflake)
    # In RPI use the provider name as the DSN name
    provider: redshift
    # ==========================
    # Configuration for Redshift
    redshift:
      connections:
        # Redshift credentials for Tenant 1
        - name: tenant1
          server: redshift-tenant1.endpoint.aws
          port: 5439
          database: db_tenant1
          username: user1
          password: pass1
        # Redshift credentials for Tenant 2
        - name: tenant2
          server: redshift-tenant2.endpoint.aws
          port: 5439
          database: db_tenant2
          username: user2
          password: pass2
          
    # ==========================
    # Configuration for BigQuery
    bigquery:
      # The Google Cloud Project ID
      projectId: my_google_project_id
      # SQL dialect option (1 = Standard SQL)
      sqlDialect: 1
      # OAuth mechanism (0 = Service Account, 1 = User Credentials)
      OAuthMechanism: 0 
      credentialsType: serviceAccount
      # Service account email
      serviceAccountEmail: my-google-svs-account@my-project.iam.gserviceaccount.com 
      # Create a ConfigMap containing the service account JSON credentials file 
      # and provide the name below
      configMapName: my-google-svs-account 
      # Name of the service account JSON key
      keyName: my-google-svs-account.json
      # Path to the service account JSON key file
      ConfigMapFilePath: /app/google-creds
      # AllowLargeResults: When set to 1, the driver allows for result sets in responses to be larger than 128 MB.
      allowLargeResults: 0
      # LargeResultsDataSetId: DatasetId to store temporary tables created.  This is a required setting if AllowLargeResults is set to 1.
      largeResultsDataSetId: _bqodbc_temp_tables
      # LargeResultsTempTableExpirationTime: Time in milliseconds before the temporary tables created expire.  
      # This is a required setting if AllowLargeResults is set to 1.
      largeResultsTempTableExpirationTime: "3600000"

    # ==========================
    # Snowflake Configuration
    #
    # This section configures access to a Snowflake data warehouse using RSA key pair authentication,
    # which provides enhanced security compared to basic authentication (username and password).
    #
    # Apply this configuration if your Snowflake instance requires RSA key-based authentication.
    # ********** This feature will be available starting with the upcoming RPI 7.7 release ****************
    snowflake:
      # Name of the ConfigMap storing Snowflake credentials
      ConfigMapName: snowflake-creds
      # Name of the RSA key for authentication
      keyName: my-snowflake-rsakey.p8
      # Mount path for the credentials in the container
      ConfigMapFilePath: /app/snowflake-creds
      # In RPI, use the following format for the Snowflake connection string:
      # User=<snowflakeUser>;Db=<snowflakeDB>;host=<snowflakeHost>;Account=<snowflake account>;AUTHENTICATOR=snowflake_jwt;PRIVATE_KEY_FILE=/app/snowflake-creds/my_snowflake_rsa_key.p8;PRIVATE_KEY_PWD=<privateKeyPassword>

# ==========================
# Certain RPI functionality (e.g., secret managers, Azure and GCP plugins) is able to make use of 
# cloud provider identity to authenticate with cloud services.
cloudIdentity:
  enabled: false
  # Authentication method for accessing cloud services.
  # Supported options: Azure, Google, Amazon
  provider: Amazon
  secretsManagement:
    enabled: false
    # Specify how to reference required secrets, such as database passwords and connection strings.
    # Supported options: 'kubernetes' or 'keyvault'
    #
    # - Use 'kubernetes' to have the Helm chart automatically create the secrets within your Kubernetes cluster.
    # - Use 'keyvault' to disable Kubernetes secret creation and pull secrets from an external key vault.
    #
    # For more information, refer to the ```Configure Secrets Management``` in the README.md
    secretsProvider: kubernetes
    # If secretsProvider is kubernetes - Let the Helm chart automatically create the secret
    autoCreateSecrets: true
    # Name of the kubernetes secret to be created
    secretName: redpoint-rpi-secrets
    # Use Key Vault for system configuration passwords
    UseForConfigPasswords: true
    UseForAppSettings: true
    # Interval in seconds to reload configuration from Key Vault
    ConfigurationReloadIntervalSeconds: 30
  azureSettings:
    # Supported options: workloadIdentity
    credentialsType: workloadIdentity
    managedIdentityClientId: your_managed_identity_client_id
    UseADTokenForDatabaseConnection: false
    # If your secretsProvider is keyvault
    vaultUri: https://myvault.vault.azure.net/
    appSettingsVaultUri: https://myvault.vault.azure.net/
  googleSettings:
    credentialsType: serviceAccount
    # Create a ConfigMap containing the service account JSON credentials file 
    # and provide the name below
    configMapName: my-google-svs-account
    keyName: my-google-svs-account.json
    ConfigMapFilePath: /app/google-creds
    serviceAccountEmail: my-google-svs-account@my-project.iam.gserviceaccount.com
    # Name of google project
    projectId: your_google_project_id
  amazonSettings:
    credentialsType: accessKey
    accessKeyId: <my-aws-iam-access-key>
    secretAccessKey: <my-aws-iam-secret-access-key>
    region: us-east-1  

# ==========================      
storage:
  # Configure storage for the RPI File Output and Data Management (RPDM) upload directories.
  # This chart is intentionally storage agnostic and does not enforce any specific storage solution.
  # You are responsible for creating the appropriate storage configuration based on your cloud providerâ€™s requirements.
  # Provide the name of the Persistent Volume Claim (PVC) to be used below.
  # If storage is not needed, set 'enabled' to false.
  persistentVolumeClaims:
    FileOutputDirectory:
      enabled: false
      claimName: rpifileoutputdir
      mountPath: /rpifileoutputdir
    Plugins:
      enabled: false
      claimName: realtimeplugins
      mountPath: /app/plugins
    DataManagementUploadDirectory:
      enabled: false
      claimName: rpdmuploaddirectory
      mountPath: /rpdmuploaddirectory

# ==========================
realtimeapi:
  # If disabled, the realtime pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  name: rpi-realtimeapi
  serviceAccount: 
    enabled: true
  # Ensure this matches your target RPI client ID.
  rpiClientID: 00000000-0000-0000-0000-000000000000
  # The default authentication method for the Realtime API is an authentication 
  # token in the header of the call to the API endpoint
  authentication:
    # Supported options are 
    # - basic
    # - oauth
    type: basic
    # With basic authentication, methods protected by the Standard role do not require an RPIAuthKey 
    # authentication token whereas the rest require a token.
    basic:
      authToken: 00000000-0000-0000-0000-000000000000
      standard: false
      forms: true
      listenerQueue: true
      recommendations: true
    # Once OAuth authentication is enabled, it takes precedence over the usage of static token authentication.
    # An RPI Realtime authentication database must be made available, and 
    # Refer to https://docs.redpointglobal.com/rpi/rpi-realtime-authentication
    oauth:
      databaseName: RPIRealtimeCore
      accessTokenLifetimeSeconds: 360
      refreshTokenLifetimeSeconds: 360
  # Expose the Realtime API Swagger page for API exploration and testing.
  enableHelpPages: true 
  enableEventListening: true
  realtimeProcessingEnabled: true
  CORSOrigins: ["*"]
  ThresholdBetweenSiteVisitsMinutes: 30
  CacheWebFormData: true
  decisionCacheDuration: 60
  enableAuditMetricsInHeaders: true
  # If set, profile data will be sent via queue to RPI
  cacheOutputQueueEnabled: true
  RealtimeServerCookieEnabled: false
  ThresholdBetweenSiteVisitsMinutes: 120
  ThresholdBetweenPageVisitsMinutes: 1
  CacheOutputCollectIPAddress: true
  CacheWebFormData: false
  HashVisitorID: false
  EventListeningLocalCacheDuration: 60
  RealtimeServerCookieHttpOnly: false
  RealtimeServerCookieName: rg-visitor
  RealtimeServerCookieExpires: 60
  RealtimeServerCookieDomain: ""
  cacheProvider:
    # This section defines the settings for the real-time cache provider.
    # Update only the fields relevant to your chosen provider and leave the others unchanged.
    # Set to true to enable real-time cache configuration.
    enabled: true  
    # Choose your cache provider
    # Supported options: (mongodb, azureredis, redis, inMemorySql, googlebigtable).
    provider: mongodb
    # If using MongoDB as the provider
    mongodb:
      # Provide the MongoDB connection string.
      connectionString: mongodb://<my_username>:<my_password>@myserver.mongodb.net:27017/Pulse?authSource=admin&ssl=true
      databaseName: <my-realtime-cache-db>
      collectionName: <my-realtime-cache-collection>

    # If using Azure Redis as the provider
    azureredis: 
      # Provide the Azure Redis server host URL.
      connectionstring: redis://<my-redis-name>.redis.cache.windows.net:6380?ssl=true&password=<my-access-key>

    # If using Redis as the provider
    redis:
      # Set to true to deploy an internal Redis container.
      # Set to false if using an external (BYO) Redis instance.
      internal: false
      replicas: 2
      # Redis connection string used when 'internal' is false.
      # Format: <hostname>:<port>,ssl=<true|false>,abortConnect=<true|false>,user=<username>,password=<password>
      connectionstring: <my-redis-hostname>:6379,ssl=True,abortConnect=false,user=<my-username>,password=<my-username>
      resources:
        enabled: true
        requests:
          cpu: 500m
          memory: 750Mi
        limits:
          cpu: 875m
          memory: 2048Mi

    # In-memory SQL cache configuration
    inMemorySql:
      # Hostname or IP address of the cache database server
      serverHost: "<my-cache-database-server-host>"
      # Name of the in-memory SQL database
      databaseName: "<my-cache-database-name>"
      # Credentials for database access
      username: "<my-cache-database-username>"
      password: "<my-cache-database-password>"
    
    googlebigtable:
      projectId: <my-bigtable-project-id>
      instanceId: <my-bigtable-instance-id>
      
  queueProvider:
    # This section defines the settings for the real-time message queue provider.
    # Set to true to enable real-time queue configuration
    enabled: true  
    # Choose your message queue provider
    # Supported options: (amazonsqs, azureservicebus, googlepubsub, azureeventhubs, rabbitmq)
    provider: amazonsqs  
    queueNames: 
      # Queues required by the RPI Realtime service
      # Ensure that you replace these values with the actual names of the queues 
      # that are allocated for your specific environment.
      formQueuePath: RPIWebFormSubmission
      eventsQueuePath: RPIWebEvents
      cacheOutputQueuePath: RPIWebCacheData
      recommendationsQueuePath: RPIWebRecommendations
      # Overrides the standard queue settings for event stream processing
      listenerQueuePath: RPIQueueListener
      callbackServiceQueuePath: RPICallbackApiQueue
    # Update only the fields relevant to your chosen provider and leave the others unchanged.
    # If using AWS SQS as the provider
    amazonsqs:
      # Specify the authentication method for accessing Amazon SQS.
      # Supported options:
      #   - accessKey: Use static AWS access key and secret key (configure these under the cloudIdentity.amazonSettings section above).
      credentialsType: accessKey
      visibilityTimeout: "301"

    # If using Azure Service Bus as the queue provider
    azureservicebus:
      # Provide the Azure Service Bus connection string
      connectionstring: Endpoint=sb://<my-service-bus-namespace>.servicebus.windows.net/;SharedAccessKeyName=<my-policy-name>;SharedAccessKey=<my-policy-key>

    # If using Google Pub/Sub as the queue provider
    googlepubsub:
      # Provide the Google Cloud project ID
      projectId: <my-google-project-id>

    # If using Azure Event Hubs as the queue provider
    azureeventhubs:
      # Provide the Azure Event Hub connection string
      connectionstring: Endpoint=sb://<my-event-hubs-namespace>.servicebus.windows.net/;SharedAccessKeyName=<my-policy-name>;SharedAccessKey=<my-policy-key>;EntityPath=<my-event-hub-name>
      eventHubName: RPIQueueListener
      SendMessageBatchSize: 200
      ReceiveMessageBatchSize: 200
      # EventHub namespace name
      NamespaceName: my_eventhub_namespace_name
      PartitionId:
        - "0"
        - "1"
    # If using RabbitMQ as the queue provider
    rabbitmq:
      # Set to true to deploy an internal Redis container.
      # Set to false if using an external (BYO) Redis instance.
      internal: false
      # Number of RabbitMQ replicas (only applicable when 'internal' is true)
      replicas: 2
      # RabbitMQ hostname or service name
      hostname: rpi-rabbitmq
      # Virtual host to use within RabbitMQ
      virtualHost: "/"
      # Credentials for RabbitMQ access
      username: redpointdev
      password: <my-secure-password>
      resources:
        enabled: true
        requests:
          cpu: 500m
          memory: 750Mi
        limits:
          cpu: 875m
          memory: 2048Mi

    # If using Amazon Managed Kafka (MSK) as the queue provider
    amazonmsk:
      region: <my-aws-region>
      accessKeyId: <my-aws-iam-access-key>
      secretAccessKey: <my-aws-iam-secret-access-key>
      bootstrapServers: <my-server1.c2.kafka.us-east-1.amazonaws.com:9198>
      Acks: None
      CompressionType: Snappy
      MaxRetryAttempt: 10
      BatchSize: "1000000"
      LingerTime: 0
      UseAwsMsk: True
  dataMaps:
    visitorProfile:
      DaysToPersist: 365
      Cache: Default
      DaysToPersist: 365
      CompressData: true
    visitorHistory:
      DaysToPersist: 365
      Cache: Default
      DaysToPersist: 365
      CompressData: true
    nonVisitorData:
      DaysToPersist: 365
      Cache: Default
      DaysToPersist: 365
      CompressData: true
    productRecommendation:
      DaysToPersist: 365
      Cache: Default
      DaysToPersist: 365
      CompressData: true
    offerHistory:
      DaysToPersist: 365
      Cache: Default
      DaysToPersist: 365
      CompressData: true
    messageHistory:
      DaysToPersist: 365
      Cache: Default
      DaysToPersist: 365
      CompressData: true
  idValidation:
    enableVisitorIDValidation: true
    visitorID:
      minimumLength: 1
      maximumLength: 36
      enableLetters: true
      enableNumbers: true
      permittedCharacters:
        - "-"
        - "_"
        - "/"
        - "."
        - "@"
        - "#"
        - "&"
        - "?"
    enableDeviceIDValidation: true
    deviceID:
      minimumLength: 1
      maximumLength: 36
      enableLetters: true
      enableNumbers: true
      permittedCharacters:
        - "-"
        - "_"
        - "/"
        - "."
        - "@"
        - "#"
        - "&"
        - "?"

  # Custom plugin configuration
  customPlugins:
    # Enable of disabled the configuration
    enabled: false
    # List of plugin definitions to inject into the application via environment variables.
    # To define multiple plugins, simply add each as a new entry in the list below.
    # To remove a plugin, simply remove the entry from the list.
    list:
      # --------------------- Pre-Decision Example
      - name: Pre-Decision Example
        factory:
          assembly: RedPoint.Realtime.Example.Plugins
          type: RealtimeExamplePlugin.Decisions.PreDecisionPluginFactory
        type:
          name: Predecision
          # Optional: Possible values are Include, Exclude
          apiContentFilterOperator: "Include" 
          # Optional: Define one or more API context filters.
          # Uncomment to add a filter.
          apiContextFilters:
            - apply-plugin
        settings:
          - key: Param1
            value: my-custom-parameter1
          - key: Param2
            value: my-custom-parameter2
          #- key: key2
          #  value: value2
          #- key: key3
          #  value: value3
          # If a setting requires a collection of values, these can be supplied as per the example below
          # Uncomment and customize the block below as needed:
          #- key: ParamList 
          #  values:
          #    - val1
          #    - val2
          #    - val3
      # --------------------- Post-Decision Example
      - name: Post-Decision Example
        factory:
          assembly: RedPoint.Realtime.Example.Plugins
          type: RealtimeExamplePlugin.Decisions.PostDecisionFactory
        type:
          name: Postdecision
          # Optional: Possible values are Include, Exclude
          apiContentFilterOperator: "" 
          # Optional: Define one or more API context filters.
          # Uncomment to add a filter.
          apiContextFilters:
          #  - filter1
        settings:
          - key: Prefix
            value: my-custom-prefix
          - key: Suffix
            value: my-custom-suffix
          #- key: key2
          #  value: value2
          #- key: key3
          #  value: value3
          # If a setting requires a collection of values, these can be supplied as per the example below
          # Uncomment and customize the block below as needed:
          #- key: ParamList 
          #  values:
          #    - val1
          #    - val2
          #    - val3
      # --------------------- Smart Asset Result Example
      - name: Smart Asset Result Plugin Example
        factory:
          assembly: RedPoint.Realtime.Example.Plugins
          type: RealtimeExamplePlugin.Decisions.SmartAssetPluginFactory
        type:
          name: SmartAssetResults
          # Optional: Possible values are Include, Exclude
          apiContentFilterOperator: "" 
          # Optional: Define one or more API context filters.
          # Uncomment to add a filter.
          apiContextFilters:
            - apply-plugin
          #  - filter2
        settings:
          - key: ParameterName1
            value: MySmartAssetPluginCounter1
          - key: ParameterName2
            value: MySmartAssetPluginCounter2
          #- key: key2
          #  value: value2
          #- key: key3
          #  value: value3
          # If a setting requires a collection of values, these can be supplied as per the example below
          # Uncomment and customize the block below as needed:
          #- key: ParamList 
          #  values:
          #    - val1
          #    - val2
          #    - val3
      # --------------------- Event Plugin Example
      - name: Event Plugin Example
        factory:
          assembly: RedPoint.Realtime.Example.Plugins
          type: RealtimeExamplePlugin.Events.EventPluginFactory
        type:
          name: Event
          # Optional: Possible values are Include, Exclude
          apiContentFilterOperator: "" 
          # Optional: Define one or more API context filters.
          # Uncomment to add a filter.
          apiContextFilters:
          #  - apply-plugin
          #  - filter2
        settings:
          - key: Param1
            value: my-custom-parameter1
          - key: Param2
            value: my-custom-parameter2
          #- key: key2
          #  value: value2
          #- key: key3
          #  value: value3
          # If a setting requires a collection of values, these can be supplied as per the example below
          # Uncomment and customize the block below as needed:
          #- key: ParamList 
          #  values:
          #    - val1
          #    - val2
          #    - val3
      # --------------------- Form Processing Plugin Example
      - name: Form Processing Plugin Example
        factory:
          assembly: RedPoint.Realtime.Example.Plugins
          type: RealtimeExamplePlugin.Forms.FormProcessingFactory
        type:
          name: FormProcessing
          # Optional: Possible values are Include, Exclude
          apiContentFilterOperator: "" 
          # Optional: Define one or more API context filters.
          # Uncomment to add a filter.
          apiContextFilters:
          #  - apply-plugin
          #  - filter2
        settings:
          - key: extrafield1
            value: my-value
          - key: extrafield2
            value: my-value
          #- key: key2
          #  value: value2
          #- key: key3
          #  value: value3
          # If a setting requires a collection of values, these can be supplied as per the example below
          # Uncomment and customize the block below as needed:
          #- key: ParamList 
          #  values:
          #    - val1
          #    - val2
          #    - val3
      # --------------------- Visitor Profile Plugin Example
      - name: Visitor Profile Plugin Example
        factory:
          assembly: RedPoint.Realtime.Example.Plugins
          type: RealtimeExamplePlugin.Visitor.VisitorCachePluginFactory
        type:
          name: Visitor
          # Optional: Possible values are Include, Exclude
          apiContentFilterOperator: "" 
          # Optional: Define one or more API context filters.
          # Uncomment to add a filter.
          apiContextFilters:
          #  - apply-plugin
          #  - filter2
        settings:
          - key: Param1
            value: my-custom-parameter
          - key: Param2
            value: my-custom-parameter
          #- key: key2
          #  value: value2
          #- key: key3
          #  value: value3
          # If a setting requires a collection of values, these can be supplied as per the example below
          # Uncomment and customize the block below as needed:
          #- key: ParamList 
          #  values:
          #    - val1
          #    - val2
          #    - val3
          
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: 500m
      memory: 750Mi
    limits:
      cpu: 875m
      memory: 2048Mi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: None
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    failureThreshold: 60
    periodSeconds: 10
    timeoutSeconds: 2

# ==========================
callbackapi:
  # If disabled, the callbackapi pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  name: rpi-callbackapi
  channelLabel: SendGrid
  serviceAccount: 
    enabled: true 
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: 500m
      memory: 750Mi
    limits:
      cpu: 875m
      memory: 2048Mi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: None
  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    failureThreshold: 60
    periodSeconds: 10
    timeoutSeconds: 2

# ==========================      
executionservice:
  # If disabled, the executionservice pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  name: rpi-executionservice
  enableRPIAuthentication: true
  serviceAccount: 
    enabled: true 
  jobExecution:
    internalAddress: ""
    auditTaskEvents: true
    maxThreadsPerExecutionService: 50
    executionShutdownWaitForActivity: "00:08:00"
    overrideCustomSQLReservedWords: false
    rpdmOApiPrefixUri: /v1/
    taskTimeout: 60
    triggerCheckCriteriaInterval: 60
    triggersMaxDaysInactive: 180
    defaultMaintenanceModeBufferTime: "00:05:00"
    workflowPrioritization:
      enabled: true
      maxConcurrentWorkflowActivities: 100
      maximumQueueTime: "24:00:00"
  seedService:
    memoryCacheSize: "10"
    maxNumberRetries: "100"
    maxRetryDelay: "00:01:00"
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: 500m
      memory: 750Mi
    limits:
      cpu: 875m
      memory: 2048Mi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: None

  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    # Available options:
    # - "keda": Enables scaling based on custom RPI metrics from Prometheus using KEDA. 
    #    Requires KEDA to be installed in your cluster.
    #    Installation guides: 
    #      - https://keda.sh/docs/latest/deploy/
    #      - https://learn.microsoft.com/en-us/azure/aks/keda-about
    #      - https://learn.microsoft.com/en-us/azure/aks/keda-workload-identity?source=recommendations
    #
    # - "hpa": Uses the native Kubernetes Horizontal Pod Autoscaler to scale
    #   based on CPU and/or memory usage. Does not require any additional components.
    # Note: **KEDA is the recommended scaling solution for the Execution Service**
    type: keda
    # HPA Settings
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
    
    # KEDA Settings
    kedaScaledObject:
       # The Prometheus server URL that KEDA will query for metrics.
      serverAddress: <my-prometheus-query-endpoint>
      # Name of the TriggerAuthentication resource for KEDA to authenticate with Prometheus.
      authenticationRef: rpi-executionservice
      # If using Azure Managed Prometheus in AKS with Workload Identity.
      # - This should be the Client ID of the User-Assigned Managed Identity (UAMI).
      # - The identity must be referenced in the TriggerAuthentication resource.
      # - Relevant Docs: https://learn.microsoft.com/en-us/azure/aks/keda-workload-identity
      identityId: <my-workload_identity-id>
      # The name of the Prometheus metric used by KEDA to make scaling decisions.
      metricName: execution_total_executing_count
      # PromQL query to fetch the current value of the custom metric.
      # Example filters:
      # - Kubernetes Namespace: "<my-rpi-namespace>"
      # - App Label: "rpi-executionservice"
      # - Azure Workload Identity Label: "true"
      # Update these labels if your namespace, app, or identity settings are different.
      query: sum(execution_total_executing_count{kubernetes_namespace=\"<my-rpi-namespace>\",app=\"rpi-executionservice\",azure_workload_identity_use=\"true\"})
      # The target value for the metric. When the metric exceeds this threshold,
      # KEDA will trigger a scale-out event.
      threshold: "80"
      # How often (in seconds) KEDA polls Prometheus for the metric value.
      pollingInterval: 30
      # The minimum number of pods to maintain at all times, even when there is little or no load.
      minReplicaCount: 2
      # The maximum number of pods KEDA can scale up to, based on the metric value and scaling policies.
      maxReplicaCount: 10
      fallback:
        failureThreshold: 3
        replicas: 2
      behavior:
        scaleUp:
          stabilizationWindowSeconds:
          policies:
            type: Percent
            value: 100
            periodSeconds: 60
        scaleDown:
          stabilizationWindowSeconds:
          policies:
            type: Percent
            value: 100
            periodSeconds: 60
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    failureThreshold: 60
    periodSeconds: 10
    timeoutSeconds: 2

# ========================== 
interactionapi: 
  # If disabled, the interactionapi pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  name: rpi-interactionapi
  enableRPIAuthentication: true
  enableSwagger: true
  serviceAccount: 
    enabled: true 
  allowSavingLoginDetails: true
  alwaysShowClientsAtLogin: true
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: 500m
      memory: 750Mi
    limits:
      cpu: 875m
      memory: 2048Mi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: None

  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    # Options: "keda" or "hpa".
    # 
    # - "keda": Enables KEDA (Kubernetes-based Event Driven Autoscaling), allowing scaling based on RPI custom metrics from
    #   Prometheus. This option assumes that KEDA is already installed in your cluster.
    #   If not, you can install it with Documentation: https://keda.sh/docs/latest/deploy/
    #
    # - "hpa": Enables the standard Kubernetes Horizontal Pod Autoscaler, which scales pods based on CPU and/or memory 
    #   usage metrics. This is natively supported by Kubernetes and does not require additional installation.
    #
    # Choose the appropriate option based on your scaling requirements. If you need scaling based on RPI custom metrics, use "keda".
    # For resource-based scaling, use "hpa".
    type: hpa
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    failureThreshold: 60
    periodSeconds: 10
    timeoutSeconds: 2

# ========================== 
integrationapi:
  # If disabled, the integrationapi pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  name: rpi-integrationapi
  enableSwagger: true
  serviceAccount: 
    enabled: true 
  enableRPIAuthentication: true
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: 500m
      memory: 750Mi
    limits:
      cpu: 875m
      memory: 2048Mi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: None

  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    # Options: "keda" or "hpa".
    # 
    # - "keda": Enables KEDA (Kubernetes-based Event Driven Autoscaling), allowing scaling based on RPI custom metrics from
    #   Prometheus. This option assumes that KEDA is already installed in your cluster.
    #   If not, you can install it with Documentation: https://keda.sh/docs/latest/deploy/
    #
    # - "hpa": Enables the standard Kubernetes Horizontal Pod Autoscaler, which scales pods based on CPU and/or memory 
    #   usage metrics. This is natively supported by Kubernetes and does not require additional installation.
    #
    # Choose the appropriate option based on your scaling requirements. If you need scaling based on RPI custom metrics, use "keda".
    # For resource-based scaling, use "hpa".
    type: hpa
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    failureThreshold: 60
    periodSeconds: 10
    timeoutSeconds: 2

# ========================== 
nodemanager:
  # If disabled, the nodemanager pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  name: rpi-nodemanager
  serviceAccount: 
    enabled: true 
  enableRPIAuthentication: true
  enableSwagger: true
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: 500m
      memory: 750Mi
    limits:
      cpu: 875m
      memory: 2048Mi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: None

  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    failureThreshold: 60
    periodSeconds: 10
    timeoutSeconds: 2

# ========================== 
deploymentapi:
  # If disabled, the deploymentapi pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  name: rpi-deploymentapi
  serviceAccount: 
    enabled: true 
  # Default resource requests and limits per deployment.
  # These values are designed to fit 8 deployments on a single node with 8 vCPUs and 16 GB RAM.
  # Treat these as starting points and adjust accordingly to meet your utilization and performance requirements.
  resources:
    enabled: true
    requests:
      cpu: 500m
      memory: 750Mi
    limits:
      cpu: 875m
      memory: 2048Mi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: None

# ==========================
queuereader: 
  # If disabled, the queuereader pod will not be deployed
  enabled: true
  # Number of pod replicas to deploy
  replicas: 1
  name: rpi-queuereader
  # Configuration for the Queue Reader container introduced in RPI v7.4
  # This component handles the draining of Queue Listener and RPI Realtime queues.
  serviceAccount: 
    enabled: true 
  # Enable or disable processing for specific queues
  isFormProcessingEnabled: true
  isEventProcessingEnabled: true
  isCacheProcessingEnabled: true
  queueListenerEnabled: true
  isCallbackServiceProcessingEnabled: true
  # Queue for storing messages received by inactive triggers.
  # You can customize the queue name as needed.
  listenerQueueNonActiveQueuePath: listenerQueueNonActive
  # Time-to-live (TTL) in days for messages in the inactive trigger queue.
  listenerQueueNonActiveTTLDays: 14
  # Queue for storing messages that encountered errors during processing.
  # You can customize the queue name as needed.
  listenerQueueErrorQueuePath: listenerQueueError
  # Time-to-live (TTL) in days for messages in the error queue.
  listenerQueueErrorTTLDays: 14
  realtimeConfiguration:
    # Distribution mode for high-performance or high-volume transactions
    # Set to true if you require distributed processing
    isDistributed: false
    distributedCache:
      # Only Redis is currently supported
      provider: Redis
      connectionString: <my-redis-connection-string>
    # Comma separated List of RPI client IDs associated with your RPI cluster 
    tenantIds: 00000000-0000-0000-0000-000000000000
  # Thread pool configuration
  threadPoolSize: 10
  # Timeout duration for processing, in minutes
  timeoutMinutes: 60
  # Maximum number of messages to process in a single batch
  maxBatchSize: 50
  useMessageLocks: true
  resources:
    enabled: true
    requests:
      cpu: 500m
      memory: 750Mi
    limits:
      cpu: 875m
      memory: 2048Mi
  service:
    # The port on which the Kubernetes services will be exposed.
    # This can be customized to align with the customer's internal port conventions.
    port: 80
  # Optional custom labels to apply to the Deployment and Pod metadata.
  # These will be added in addition to the default labels.
  # Example: environment: prod, team: marketing
  customLabels: 
    environment: "prod"
    team: "marketing"
  customAnnotations:
    my-custom-annotation: "my-value"
  customMetrics:
    # Enable or disable custom Prometheus metrics scraping for this service
    enabled: false
    # When enabled, the following annotation will be added to the pod metadata
    # to allow Prometheus scrape the /metrics endpoint
    prometheus_scrape: false
  # Set the minimum log level for application logging.
  # Supported options: Critical, Error, Warning, Information, Trace, Debug
  logging:
    default: Error
    database: Error
    rpiTrace: Error
    rpiError: Error
    Console: None

  # Enable Horizontal autoscaling
  autoscaling:
    enabled: true
    type: hpa
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
  # Liveness probe checks if the app is still running. 
  # If it fails, the pod will be restarted.
  livenessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Readiness probe checks if the app is ready to receive traffic. 
  # If it fails, traffic is paused.
  readinessProbe:
    initialDelaySeconds: 5
    periodSeconds: 10
    failureThreshold: 3
    timeoutSeconds: 2
  # Startup probe checks if the app has finished starting.
  # Until it passes, liveness and readiness probes are ignored.
  startupProbe:
    failureThreshold: 60
    periodSeconds: 10
    timeoutSeconds: 2

diagnosticsMode:
  # Enable or disable copying diagnostic logs to Azure Blob Storage
  copytoAzureBlob: 
    enabled: false
    accountName: <yourstorageaccount>
    accessKey: <yourstorageaccount-access-key>
    containerName: <yourstorageaccount-container-name>
    blobServiceEndpoint: https://yourstorage.blob.core.windows.net
    enableCdn: false
    UseDataLakeStorageGen2: false
  # Enable or disable copying diagnostic logs to an SFTP server
  copytoSftp: 
    enabled: false
    sftpHost: <your-sftp-host>
    sftpUsername: <your-sftp-username>
    sftpPassword: <your-sftp-password>
    sftpPort: "22" # <your-sftp-port>
  dotNetTools: 
    enabled: false
    useGcDump: false
    useCounters: false
    useDotNetTools__Path: /app/.dotnet-tools

OpenIdProviders:
  # Set to true to enable OpenID Connect settings.
  enabled: false
  # Name of the OpenID Connect provider. Supported Providers 
  # - KeyCloak
  # - Okta
  # - AzureAD
  # https://docs.redpointglobal.com/rpi/admin-authentication
  name: AzureAD
  # Authorization host for OpenID Connect
  authorizationHost: https://login.microsoftonline.com/00000000-0000-0000-0000-000000000000/v2.0
  # The Client ID configured within the OpenID provider.
  clientID: 00000000-0000-0000-0000-000000000000
  # Audience for the OpenID Connect authentication request
  audience: api://00000000-0000-0000-0000-000000000000
  # The redirect URL used for retrieving the token, as configured within the OpenID provider.
  redirectURL: https://rpi-interactionapi.example.com
  # Enable or disable refresh tokens
  #  - If refresh tokens are disabled, the client will be logged off once the token expires,
  #  - per the period configured within the OpenID provider.
  enableRefreshTokens: true
  # Validate issuer of the OpenID Connect provider
  #  - When set to true, validates issuer of the OpenID Connect provider 
  #  - (i.e., the authorizationHost must match the issuer name supplied in the access token).
  validateIssuer: false
  # Validate audience of the OpenID Connect provider
  #  - When set to true, validates audience of the OpenID Connect provider 
  #  - (i.e., the audience must match the audience name supplied in the access token)
  validateAudience: true
  # Parameter for id_token_hint during logout
  logoutIdTokenParameter: id_token_hint
  # Custom scopes for OpenID Connect
  #  - This is the list of custom scopes required to request the OpenID access token.
  customScopes: 
  - api://00000000-0000-0000-0000-000000000000/Interaction.Clients
  # Enable or disable management of RPI users directly within OIDC provider (as well as native user management
  supportsUserManagement: false

SMTPSettings:
  SMTP_SenderAddress: noreply-rpi@example.com
  SMTP_Address: your_smtp_host
  SMTP_Port: 587
  EnableSSL: true
  UseCredentials: true
  SMTP_Username: your_smtp_server_username
  SMTP_Password: your_smtp_server_password

# ========================== 
ingress:
  controller:
    # Set enabled to false if you want to disable the creation of the ingress controller
    enabled: true 
  # Set mode to internal for private ingress and public for public ingress
  mode: public 
  # Set certificateSource to acm if your certificate is managed in AWS Certificate Manager 
  privateLink:
    azure:
      enabled: false
  certificateSource: kubernetes # acm
  tlsSecretName: ingress-tls
  className: nginx-redpoint-rpi
  # Subnet name is only required if you set the ingress mode to private
  subnetName: <my-ingress-vpc-subnet-name> 
  # Certificate Arn is only required if you set the certificateSource to acm
  certificateArn: your_acm_certificate_arn
  # Specify the domain name for the ingress resources.
  domain: example.com
  # Add any specific annotations required for your ingress setup here.
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: 4096m
    nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
    nginx.ingress.kubernetes.io/enable-access-log: "true"

  customLabels: 
    environment: prod
    team: marketing
  service:
    port: 80
  customAnnotations:
    prometheus.io/scrape: "false"
  # Define hostnames for different services in your application.
  hosts:
    # Deployment API
    config: rpi-deploymentapi
    # Interaction API
    client: rpi-interactionapi
    # Integration API
    integration: rpi-integrationapi
    # Realtime API 
    realtime: rpi-realtimeapi
    # Callback API
    callbackapi: rpi-callbackapi
    # Queue Reader 
    queuereader: rpi-queuereader
    # RabbitMQ console
    rabbitmqconsole: rpi-rabbitmq-console

securityContext:
  # Enable this to enforce running the container as a non-root user.
  enabled: true
  runAsUser: 7777
  runAsGroup: 7777
  fsGroup: 7777
  runAsNonRoot: true
  readOnlyRootFilesystem: false
  privileged: false
  allowPrivilegeEscalation: false
  capabilities:
    drop: ["ALL"]

# NodeSelector is used to control scheduling by specifying node labels.
# When enabled, the deployment will only be scheduled on nodes that match the provided key-value pair.
nodeSelector:
  enabled: false
  key: app
  value: redpoint-rpi

# Tolerations allow the deployment to be scheduled on tainted nodes.
# When enabled, this ensures that the workload can run on nodes explicitly reserved for Redpoint RPI by tolerating their taints.
tolerations:
  enabled: false
  effect: NoSchedule
  key: app
  operator: Equal
  value: redpoint-rpi

# ==========================
redpointAI:
  # Set to true to enable Redpoint AI features
  enabled: false  
  naturalLanguage:
    # your OpenAI API key
    ApiKey: <my-openai-key>
    # Base URL for the OpenAI endpoint             
    ApiBase: https://example.openai.azure.com/
    # API version (e.g., 2023-05-15)            
    ApiVersion: 2023-07-01-preview
    # Name of the deployed ChatGPT engine (e.g., gpt-35-turbo)           
    ChatGptEngine: gpt-4-32k
    # Temperature for ChatGPT responses (e.g., 0.7)        
    ChatGptTemp: 0.5
  cognitiveSearch:
    # Azure Cognitive Search endpoint URL
    SearchEndpoint: https://example.search.windows.net
    # API key for Azure Cognitive Search       
    SearchKey: <my-cognitivesearch-key>
    # Azure Cognitive Search vector profile name    
    VectorSearchProfile: vector-profile-000000000000
    # Azure Cognitive Search vector config name 
    VectorSearchConfig: vector-config-000000000000 
  modelStorage:
    # Azure Blob Storage connection string for model artifacts
    ConnectionString: DefaultEndpointsProtocol=https;AccountName=my_account_name;AccountKey=my_account_access_key 
    # Name of the embeddings model (e.g., text-embedding-ada-002)
    EmbeddingsModel: text-embedding-ada-002
    # Dimensionality of the embeddings (e.g., 1536)            
    ModelDimensions: 1536 
    # Name of the Azure Blob Storage container holding vector index data
    ContainerName: my_blob_container_name
    # Path inside the container where model files are stored       
    BlobFolder: my_blob_container_folder_name